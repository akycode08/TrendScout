"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª TrendScout

–≠—Ç–æ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. –û—Ç—Å—é–¥–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω.
"""

import asyncio
import sys
from config import get_settings
from database.db import init_db
from data_collectors import GoogleTrendsCollector, TikTokCollector, RedditCollector, YouTubeCollector
from analyzers import DataFilter, AIAnalyzer, TrendScorer, TrendFinder


async def run_pipeline(vertical: str = "coffee", location: str = None):
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω TrendScout.
    
    –ü–æ–∫–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ —à–∞–≥–∞:
    1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (Google Trends)
    2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        vertical: –¢–∏–ø –±–∏–∑–Ω–µ—Å–∞ (coffee, restaurant, etc.)
        
    Returns:
        List[Dict]: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ TrendScout –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª–∏: {vertical}")
    print("=" * 60)
    
    # 1. –°–ë–û–† –î–ê–ù–ù–´–•
    print("\nüì• –®–ê–ì 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö")
    print("-" * 60)
    
    # –ö–æ–ª–ª–µ–∫—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    collectors = [
        GoogleTrendsCollector(),  # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ, –±–µ–∑ API –∫–ª—é—á–µ–π
        RedditCollector(),        # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç Reddit API –∫–ª—é—á–∏
        YouTubeCollector(),       # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç YouTube API –∫–ª—é—á
        TikTokCollector(),        # –¢—Ä–µ–±—É–µ—Ç APIFY_API_KEY (–ø–ª–∞—Ç–Ω–æ)
        # TODO: InstagramCollector(),  # –¢—Ä–µ–±—É–µ—Ç APIFY_API_KEY (–ø–ª–∞—Ç–Ω–æ)
    ]
    
    raw_data = []
    for collector in collectors:
        try:
            # –ü–µ—Ä–µ–¥–∞–µ–º location —Ç–æ–ª—å–∫–æ –¥–ª—è Google Trends (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç)
            if isinstance(collector, GoogleTrendsCollector):
                data = await collector.collect(vertical=vertical, location=location)
            else:
                data = await collector.collect(vertical=vertical)
            raw_data.extend(data)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {collector.__class__.__name__}: {e}")
            continue
    
    if not raw_data:
        print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
        return []
    
    # 2. –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ò –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø
    print("\nüîç –®–ê–ì 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è")
    print("-" * 60)
    
    filtered_data = DataFilter.filter_and_normalize(
        raw_data, 
        vertical=vertical,
        hours=48  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 48 —á–∞—Å–æ–≤
    )
    
    # 3. –ü–û–ò–°–ö –¢–†–ï–ù–î–û–í
    print("\nüîç –®–ê–ì 3: –ü–æ–∏—Å–∫ –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤")
    print("-" * 60)
    
    analyzed_data = filtered_data
    trends = []
    
    # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI –∞–Ω–∞–ª–∏–∑, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
    use_ai = True
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Claude API
        analyzed_data = await AIAnalyzer.analyze_batch(filtered_data, batch_size=5)
        print(f"   ‚úÖ AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(analyzed_data)} –ø–æ—Å—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        print("   –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑...")
        use_ai = False
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
    try:
        trends = TrendFinder.find_trends(analyzed_data, use_ai_analysis=use_ai)
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(trends)}")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
        trends = TrendFinder.filter_relevant_trends(trends, vertical, min_posts=1)
        print(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(trends)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
        trends = []
    
    # 4. –û–¶–ï–ù–ö–ê –¢–†–ï–ù–î–û–í (UTS –∞–ª–≥–æ—Ä–∏—Ç–º)
    print("\nüìä –®–ê–ì 4: –û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤ (UTS –∞–ª–≥–æ—Ä–∏—Ç–º)")
    print("-" * 60)
    
    scored_trends = []
    top_3_trends = []
    
    if trends:
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–¥—ã —á–µ—Ä–µ–∑ UTS –∞–ª–≥–æ—Ä–∏—Ç–º
        scored_trends = TrendScorer.score_trends(trends)
        print(f"   –û—Ü–µ–Ω–µ–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(scored_trends)}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ UTS score (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
        scored_trends = sorted(scored_trends, key=lambda x: x.get('uts_score', 0), reverse=True)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-3
        top_3_trends = scored_trends[:3]
        print(f"   –¢–æ–ø-3 —Ç—Ä–µ–Ω–¥–∞ –≤—ã–±—Ä–∞–Ω—ã!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫–∏
        for i, trend in enumerate(top_3_trends, 1):
            print(f"\n   {i}. {trend.get('trend_name', 'Unknown')}")
            print(f"      UTS Score: {trend.get('uts_score', 0):.2f}/100")
            print(f"      Velocity: {trend.get('velocity_score', 0):.2f}")
            print(f"      Engagement: {trend.get('engagement_score', 0):.2f}")
    else:
        print("   ‚ö†Ô∏è  –ù–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–Ω—É–∂–µ–Ω AI –∞–Ω–∞–ª–∏–∑)")
    
    # 5. –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–î–ï–ô (TODO)
    print("\nüí° –®–ê–ì 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–∏–¥–µ–π")
    print("-" * 60)
    print("‚è≥ –ü–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (—Ç—Ä–µ–±—É–µ—Ç—Å—è Claude API –∫–ª—é—á)")
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 60)
    print(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"   –°–æ–±—Ä–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {len(raw_data)}")
    print(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_data)}")
    if trends:
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(trends)}")
        print(f"   –¢–æ–ø-3 —Ç—Ä–µ–Ω–¥–∞: {len(top_3_trends)}")
    print("=" * 60)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 —Ç—Ä–µ–Ω–¥–∞
    if top_3_trends:
        print("\nüî• –¢–û–ü-3 –¢–†–ï–ù–î–ê (–ø–æ UTS Score):")
        for i, trend in enumerate(top_3_trends, 1):
            print(f"\n   {i}. {trend.get('trend_name', 'Unknown')}")
            print(f"      UTS Score: {trend.get('uts_score', 0):.2f}/100 ‚≠ê")
            print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {trend.get('category', 'N/A')}")
            print(f"      –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {trend.get('viral_potential', 0)}/10")
            print(f"      –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {trend.get('sentiment', 'N/A')}")
            print(f"      –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã: {', '.join(trend.get('platforms', []))}")
            print(f"      –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {trend.get('total_views', 0):,}")
            print(f"      –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:")
            print(f"        - Velocity: {trend.get('velocity_score', 0):.2f}")
            print(f"        - Momentum: {trend.get('momentum_score', 0):.2f}")
            print(f"        - Engagement: {trend.get('engagement_score', 0):.2f}")
    elif trends:
        print("\nüî• –ù–ê–ô–î–ï–ù–ù–´–ï –¢–†–ï–ù–î–´:")
        for i, trend in enumerate(trends[:5], 1):
            print(f"\n   {i}. {trend.get('trend_name', 'Unknown')}")
            print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {trend.get('category', 'N/A')}")
            print(f"      –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {trend.get('viral_potential', 0)}/10")
            print(f"      –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {trend.get('sentiment', 'N/A')}")
            print(f"      –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã: {', '.join(trend.get('platforms', []))}")
            print(f"      –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {trend.get('total_views', 0):,}")
    elif analyzed_data:
        print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        for i, item in enumerate(analyzed_data[:3], 1):
            print(f"\n   {i}. {item.get('platform', 'unknown').upper()}")
            print(f"      –ö–æ–Ω—Ç–µ–Ω—Ç: {item.get('content', '')[:50]}...")
            ai_analysis = item.get('ai_analysis', {})
            if ai_analysis:
                print(f"      –¢—Ä–µ–Ω–¥: {ai_analysis.get('item_name', 'N/A')}")
                print(f"      –ü—Ä–∏–º–µ–Ω–∏–º–æ: {ai_analysis.get('restaurant_applicable', False)}")
    
    return {
        'analyzed_data': analyzed_data,
        'trends': trends,
        'scored_trends': scored_trends,
        'top_3': top_3_trends
    }


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        settings = get_settings()
        print(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        print(f"   –í–µ—Ä—Ç–∏–∫–∞–ª—å: {settings.vertical}")
        print(f"   –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {settings.database_url}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (—Å–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã)
        print("\nüì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        init_db()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        print(f"\nüîÑ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞...")
        results = asyncio.run(run_pipeline(vertical=settings.vertical, location=settings.location))
        
        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ù–∞–π–¥–µ–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(results)}")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        print("\nüí° –ü–æ–¥—Å–∫–∞–∑–∫–∏:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª .env —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: pip install -r requirements.txt")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ")
        sys.exit(1)


if __name__ == "__main__":
    main()

